{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 2: Download and Prepare Synthetic Speech Commands Dataset\n",
    "\n",
    "This notebook downloads the [Synthetic Speech Commands Dataset](https://www.kaggle.com/datasets/jbuchner/synthetic-speech-commands-dataset) from Kaggle and prepares it for training.\n",
    "\n",
    "**Steps:**\n",
    "1.  **Set up Kaggle API**: Ensure you have `kaggle.json` configured.\n",
    "2.  **Download and Unzip**: Download and extract the dataset files.\n",
    "3.  **Process and Prepare Data**: Convert `.wav` files to Mel Spectrograms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import kaggle\n",
    "import shutil\n",
    "\n",
    "# 1. Download Dataset\n",
    "print('Downloading synthetic-speech-commands-dataset from Kaggle...')\n",
    "dataset_slug = 'jbuchner/synthetic-speech-commands-dataset'\n",
    "download_path = './datasets/synthetic-speech-commands'\n",
    "\n",
    "if os.path.exists(download_path):\n",
    "    shutil.rmtree(download_path)\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "kaggle.api.dataset_download_files(dataset_slug, path=download_path, unzip=True)\n",
    "\n",
    "print(f'Dataset successfully downloaded and unzipped to: {download_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "import joblib\n",
    "\n",
    "# --- Parameters ---\n",
    "sample_rate = 16000\n",
    "duration = 1.0\n",
    "n_mels = 256\n",
    "desired_frames = 61\n",
    "\n",
    "# --- Command categorization ---\n",
    "# Based on 'Drone Research' document\n",
    "movement_phrases = ['backward', 'forward', 'up', 'down', 'go', 'left', 'right', 'follow']\n",
    "emergency_phrases = ['stop', 'yes', 'no']\n",
    "# No 'other' category specified for this dataset in the document\n",
    "\n",
    "# --- Initialize lists ---\n",
    "x_data = []\n",
    "y_labels = []\n",
    "data_path = download_path\n",
    "\n",
    "print(\"Processing audio files...\")\n",
    "for keyword_folder in os.listdir(data_path):\n",
    "    keyword_path = os.path.join(data_path, keyword_folder)\n",
    "    if not os.path.isdir(keyword_path):\n",
    "        continue\n",
    "        \n",
    "    if keyword_folder in emergency_phrases:\n",
    "        label = 'emergency'\n",
    "    elif keyword_folder in movement_phrases:\n",
    "        label = 'movement'\n",
    "    else:\n",
    "        continue # Skip unused words\n",
    "        \n",
    "    for file in os.listdir(keyword_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            y_labels.append(label)\n",
    "            path = os.path.join(keyword_path, file)\n",
    "            \n",
    "            # Load and process audio\n",
    "            audio, _ = librosa.load(path, sr=sample_rate, duration=duration)\n",
    "            if len(audio) < sample_rate:\n",
    "                audio = np.pad(audio, (0, sample_rate - len(audio)))\n",
    "            else:\n",
    "                audio = audio[:sample_rate]\n",
    "\n",
    "            # Feature extraction\n",
    "            mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
    "            mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "            mel_spec_db = mel_spec_db / 80.0 + 1.0\n",
    "            x_data.append(mel_spec_db)\n",
    "\n",
    "print(\"Data processing complete.\")\n",
    "\n",
    "# --- Convert, reshape, and save ---\n",
    "x_train = np.array(x_data)\n",
    "x_train = x_train[..., np.newaxis]\n",
    "current_frames = x_train.shape[2]\n",
    "if current_frames < desired_frames:\n",
    "    pad_width = ((0, 0), (0, 0), (0, desired_frames - current_frames), (0, 0))\n",
    "    x_train = np.pad(x_train, pad_width, mode='constant')\n",
    "elif current_frames > desired_frames:\n",
    "    x_train = x_train[:, :, :desired_frames, :]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_doa_int = label_encoder.fit_transform(y_labels)\n",
    "y_doa = to_categorical(y_doa_int)\n",
    "y_sed = np.ones((len(y_doa), 1))\n",
    "\n",
    "output_dir = './processed_data/synthetic-speech-commands'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "np.save(os.path.join(output_dir, 'x_train.npy'), x_train)\n",
    "np.save(os.path.join(output_dir, 'y_doa.npy'), y_doa)\n",
    "np.save(os.path.join(output_dir, 'y_sed.npy'), y_sed)\n",
    "joblib.dump(label_encoder, os.path.join(output_dir, 'label_encoder.joblib'))\n",
    "\n",
    "print(f\"\\nâœ… Processed data saved to: {output_dir}\")\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"y_doa shape: {y_doa.shape}\")\n",
    "print(f\"Classes: {label_encoder.classes_}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
