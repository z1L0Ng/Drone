{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook 3: Download and Prepare ESC-50 Dataset (Background Noise)\n",
    "\n",
    "This notebook downloads the [ESC-50 dataset](https://github.com/karolpiczak/ESC-50) from GitHub to be used for background noise in data augmentation.\n",
    "\n",
    "**Steps:**\n",
    "1.  **Clone Repository**: Use `git` to clone the repository containing the audio files.\n",
    "2.  **Prepare Augmentation Function**: A function is provided to mix these noise files with a clean speech dataset to create a more robust training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# 1. Clone GitHub Repository\n",
    "print('Cloning ESC-50 dataset from GitHub...')\n",
    "repo_url = 'https://github.com/karolpiczak/ESC-50.git'\n",
    "clone_path = './datasets/ESC-50'\n",
    "\n",
    "if os.path.exists(clone_path):\n",
    "    print('Repository already exists, skipping clone.')\n",
    "\n",
    "print(f'Dataset successfully downloaded to: {clone_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Augmentation Function\n",
    "\n",
    "This function takes a directory of clean speech files and the directory of noise files, mixing them at a specified Signal-to-Noise Ratio (SNR) to generate augmented training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import random\n",
    "\n",
    "def augment_with_noise(clean_audio_dir, noise_audio_dir, output_dir, snr_db=10):\n",
    "    \"\"\"\n",
    "    Augments a clean audio dataset by mixing it with random noise files.\n",
    "\n",
    "    Args:\n",
    "        clean_audio_dir (str): Path to the directory with clean audio folders.\n",
    "        noise_audio_dir (str): Path to the directory with noise .wav files.\n",
    "        output_dir (str): Path to save the augmented audio.\n",
    "        snr_db (int): Desired Signal-to-Noise Ratio in dB.\n",
    "    \"\"\"\n",
    "    if os.path.exists(output_dir):\n",
    "        shutil.rmtree(output_dir)\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    noise_files = [f for f in os.listdir(noise_audio_dir) if f.endswith('.wav')]\n",
    "    if not noise_files:\n",
    "        print(f\"Error: No noise files found in {noise_audio_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f'Starting augmentation with SNR = {snr_db} dB...')\n",
    "    for keyword_folder in os.listdir(clean_audio_dir):\n",
    "        keyword_path = os.path.join(clean_audio_dir, keyword_folder)\n",
    "        if not os.path.isdir(keyword_path):\n",
    "            continue\n",
    "        \n",
    "        output_keyword_path = os.path.join(output_dir, keyword_folder)\n",
    "        os.makedirs(output_keyword_path, exist_ok=True)\n",
    "\n",
    "        for clean_file in os.listdir(keyword_path):\n",
    "            if clean_file.endswith('.wav'):\n",
    "                # Load clean audio\n",
    "                clean_path = os.path.join(keyword_path, clean_file)\n",
    "                speech, sr = librosa.load(clean_path, sr=16000)\n",
    "                \n",
    "                # Load random noise\n",
    "                noise_file = random.choice(noise_files)\n",
    "                noise_path = os.path.join(noise_audio_dir, noise_file)\n",
    "                noise, _ = librosa.load(noise_path, sr=sr)\n",
    "                \n",
    "                # Ensure noise is long enough\n",
    "                while len(noise) < len(speech):\n",
    "                    noise = np.concatenate([noise, noise])\n",
    "                \n",
    "                # Trim noise to match speech length\n",
    "                start = random.randint(0, len(noise) - len(speech))\n",
    "                noise = noise[start:start + len(speech)]\n",
    "                \n",
    "                # Calculate powers and mix\n",
    "                speech_power = np.mean(speech**2)\n",
    "                noise_power = np.mean(noise**2)\n",
    "                snr = 10**(snr_db / 10)\n",
    "                scale = np.sqrt(speech_power / (snr * noise_power))\n",
    "                noisy_speech = speech + noise * scale\n",
    "                \n",
    "                # Save augmented file\n",
    "                output_file_path = os.path.join(output_keyword_path, f\"noisy_{clean_file}\")\n",
    "                sf.write(output_file_path, noisy_speech, sr)\n",
    "    \n",
    "    print(f\"âœ… Augmentation complete. Noisy files saved in: {output_dir}\")\n",
    "\n",
    "# --- Example Usage ---\n",
    "# This will create a new directory with noisy versions of the clean speech commands.\n",
    "# You can then run the preprocessing steps from Notebook 1 on this new directory.\n",
    "clean_data_dir = './datasets/speech-commands/speech_commands' \n",
    "noise_data_dir = './datasets/ESC-50/audio'\n",
    "augmented_output_dir = './datasets/speech-commands-augmented'\n",
    "\n",
    "augment_with_noise(clean_data_dir, noise_data_dir, augmented_output_dir, snr_db=15)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
