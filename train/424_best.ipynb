{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9e9594d-9d00-4969-b90a-3ea04631adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.enable_tensor_float_32_execution(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a69384e-84d5-40e6-a661-c7e4e3125a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No GPU found.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "   \n",
    "        tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "        \n",
    "       \n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[1],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=32768)]\n",
    "        )\n",
    "\n",
    "      \n",
    "        \n",
    "        print(f\"Successfully configured GPU {gpus[1]} with memory limit of 2048MB and memory growth enabled.\")\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(\"Error during GPU configuration:\", e)\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "076d2c1e-ca1d-4967-b0ba-d5c2bb7df0e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "84baf1ae-0231-45c7-a8ce-bb60c4a42e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus, 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "148160b6-c747-4526-ad2c-31026082060b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "Result of matrix multiplication: \n",
      " [[1. 3.]\n",
      " [3. 7.]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(\"Result of matrix multiplication: \\n\", c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58b98d5e-5e37-4108-9cba-8baf45748c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers import (\n",
    "    Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout,\n",
    "    Permute, Reshape, Bidirectional, GRU, TimeDistributed, Dense,\n",
    "    LayerNormalization, Add, MultiHeadAttention, GlobalAveragePooling1D\n",
    ")\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Reshape, Permute, GlobalAveragePooling1D, Add, LayerNormalization, MultiHeadAttention\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Permute, Reshape, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ddcec7c-22db-4a23-8523-6f578e49a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import MultiHeadAttention, Dense, LayerNormalization, Conv1D, Add, Dropout\n",
    "\n",
    "# def conformer_block(x, head_size, num_heads, ff_dim, dropout=0.1, kernel_size=31):\n",
    "#     # Feed Forward Module (first half)\n",
    "#     ff1 = Dense(ff_dim, activation='relu')(x)\n",
    "#     ff1 = Dropout(dropout)(ff1)\n",
    "#     ff1 = Dense(x.shape[-1])(ff1)\n",
    "#     x = Add()([x, 0.5 * ff1])\n",
    "\n",
    "#     # Multi-Head Self Attention Module\n",
    "#     attn = LayerNormalization(epsilon=1e-6)(x)\n",
    "#     attn = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(attn, attn)\n",
    "#     attn = Dropout(dropout)(attn)\n",
    "#     x = Add()([x, attn])\n",
    "\n",
    "#     # Convolution Module\n",
    "#     conv = LayerNormalization(epsilon=1e-6)(x)\n",
    "#     conv = Conv1D(filters=x.shape[-1], kernel_size=1, padding='same', activation='relu')(conv)\n",
    "#     conv = Conv1D(filters=x.shape[-1], kernel_size=kernel_size, padding='same', activation='relu', groups=x.shape[-1])(conv)\n",
    "#     conv = Conv1D(filters=x.shape[-1], kernel_size=1, padding='same')(conv)\n",
    "#     conv = Dropout(dropout)(conv)\n",
    "#     x = Add()([x, conv])\n",
    "\n",
    "#     # Feed Forward Module (second half)\n",
    "#     ff2 = Dense(ff_dim, activation='relu')(x)\n",
    "#     ff2 = Dropout(dropout)(ff2)\n",
    "#     ff2 = Dense(x.shape[-1])(ff2)\n",
    "#     x = Add()([x, 0.5 * ff2])\n",
    "\n",
    "#     # Final Layer Norm\n",
    "#     x = LayerNormalization(epsilon=1e-6)(x)\n",
    "#     return x\n",
    "import tensorflow as tf\n",
    "from keras.layers import LayerNormalization, Dense, Dropout, MultiHeadAttention, Conv1D, Add, Multiply, Lambda, Activation, DepthwiseConv1D, BatchNormalization\n",
    "\n",
    "def branchformer_block(x, head_size, num_heads, ff_dim, dropout=0.1, kernel_size=31, block_idx=0):\n",
    "    prefix = f\"branchformer{block_idx}\"\n",
    "\n",
    "    # FFN Module (first half)\n",
    "    ff1 = Dense(ff_dim, activation='relu', name=f\"{prefix}_ff1_dense1\")(x)\n",
    "    ff1 = Dropout(dropout, name=f\"{prefix}_ff1_dropout\")(ff1)\n",
    "    ff1 = Dense(x.shape[-1], name=f\"{prefix}_ff1_dense2\")(ff1)\n",
    "    x = Add(name=f\"{prefix}_ff1_add\")([x, Lambda(lambda z: 0.5 * z)(ff1)])\n",
    "\n",
    "    # Multi-Head Attention Branch\n",
    "    x_ln_attn = LayerNormalization(epsilon=1e-6, name=f\"{prefix}_attn_ln\")(x)\n",
    "    attn_out = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=head_size,\n",
    "        dropout=dropout,\n",
    "        name=f\"{prefix}_attn\"\n",
    "    )(x_ln_attn, x_ln_attn)\n",
    "    attn_out = Dropout(dropout, name=f\"{prefix}_attn_dropout\")(attn_out)\n",
    "\n",
    "    # Convolution Branch\n",
    "    conv_input = LayerNormalization(epsilon=1e-6, name=f\"{prefix}_conv_ln\")(x)\n",
    "\n",
    "\n",
    "    conv_u = Conv1D(filters=x.shape[-1], kernel_size=1, padding='same', name=f\"{prefix}_conv_u\")(conv_input)\n",
    "    conv_v = Conv1D(filters=x.shape[-1], kernel_size=1, padding='same', activation='sigmoid', name=f\"{prefix}_conv_v\")(conv_input)\n",
    "    \n",
    "    # Create the Gated Linear Unit output\n",
    "    conv_glu = Multiply(name=f\"{prefix}_glu_out\")([conv_u, conv_v])\n",
    "    # --- END OF CORRECTION ---\n",
    "\n",
    "    # Depthwise Conv\n",
    "    conv_dw = DepthwiseConv1D(kernel_size=kernel_size, padding='same', name=f\"{prefix}_depthwise\")(conv_glu)\n",
    "    conv_dw = BatchNormalization(name=f\"{prefix}_dw_bn\")(conv_dw)\n",
    "    conv_dw = Activation('swish', name=f\"{prefix}_swish\")(conv_dw)\n",
    "    \n",
    "    # Pointwise Conv + Dropout\n",
    "    conv_out = Conv1D(filters=x.shape[-1], kernel_size=1, padding='same', name=f\"{prefix}_conv_pw2\")(conv_dw)\n",
    "    conv_out = Dropout(dropout, name=f\"{prefix}_conv_dropout\")(conv_out)\n",
    "    \n",
    "    # Merge Branches\n",
    "    merged = Add(name=f\"{prefix}_merge\")([attn_out, conv_out])\n",
    "    x = Add(name=f\"{prefix}_residual_merge\")([x, merged])\n",
    "\n",
    "    # FFN Module (second half)\n",
    "    ff2 = Dense(ff_dim, activation='relu', name=f\"{prefix}_ff2_dense1\")(x)\n",
    "    ff2 = Dropout(dropout, name=f\"{prefix}_ff2_dropout\")(ff2)\n",
    "    ff2 = Dense(x.shape[-1], name=f\"{prefix}_ff2_dense2\")(ff2)\n",
    "    x = Add(name=f\"{prefix}_ff2_add\")([x, Lambda(lambda z: 0.5 * z)(ff2)])\n",
    "\n",
    "    # Final Layer Norm\n",
    "    x = LayerNormalization(epsilon=1e-6, name=f\"{prefix}_ln_out\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9237601-7238-4e4d-989f-e344c3dbd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.backend as K\n",
    "\n",
    "def masked_categorical_crossentropy(y_true, y_pred):\n",
    "\n",
    "    # categorical_crossentropy (None, 8)\n",
    "    loss = K.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "    \n",
    "    mask = K.cast(K.any(y_true > 0, axis=-1), K.floatx())  # (None,)\n",
    "\n",
    "    #  Loss\n",
    "    masked_loss = loss * mask  # (None, 8) * (None,) -> (None, 8)\n",
    "\n",
    "    valid_samples = K.maximum(K.sum(mask), 1.0)  \n",
    "\n",
    "\n",
    "    return K.sum(masked_loss) / valid_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002b8ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data loading...\n",
      "Warning: Directory not found, skipping: /Users/zilongzeng/Research/Drone/datasets_prepare/datasets/speech-commands/clean_audio\n",
      "Warning: Directory not found, skipping: /Users/zilongzeng/Research/Drone/datasets_prepare/datasets/speech-commands/noisy_audio\n",
      "Data loading complete.\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 126\u001b[39m\n\u001b[32m    124\u001b[39m x_train = np.array(x_data)\n\u001b[32m    125\u001b[39m x_train = x_train[..., np.newaxis]\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m current_frames = \u001b[43mx_train\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m current_frames < desired_frames:\n\u001b[32m    128\u001b[39m     pad_width = ((\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m), (\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m), (\u001b[32m0\u001b[39m, desired_frames - current_frames), (\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m))\n",
      "\u001b[31mIndexError\u001b[39m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "'''PREPROCESSING BLOCK'''\n",
    "# wav -> stft -> mel spec -> \n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#DATA = \"/Users/neilkalipersad/Desktop/Research Lab Files/ML Program Code/all_audio/\"\n",
    "DATA = \"/Users/zilongzeng/Research/Drone/processed_data/speech-commands\"\n",
    "SETS_TO_PROCESS = ['clean_audio', 'noisy_audio']\n",
    "\n",
    "# --- Parameters ---\n",
    "sample_rate = 16000\n",
    "duration = 1.0 \n",
    "n_mels = 256\n",
    "desired_frames = 61\n",
    "\n",
    "# --- Initialize empty lists ---\n",
    "x_data = []\n",
    "y_labels = []\n",
    "\n",
    "emergency_phrases = [\n",
    "                    #stop\n",
    "                    'stop','stop flying', 'halt', 'freeze', 'cease', 'terminate', 'abort', 'wait', 'stay', 'pause', 'hold', 'brake', 'end', 'cut', \n",
    "\n",
    "                     #no\n",
    "                    'no', 'nope',\n",
    "                    \n",
    "                    #screams\n",
    "                    'ahh', 'ah', 'woah', 'wow',\n",
    "                    \n",
    "                    #profanity\n",
    "                    'shit', 'fuck', 'god', 'damn' 'crap'\n",
    "                     \n",
    "                     ]\n",
    "movement_phrases = [\n",
    "                    #general\n",
    "                    'hover', 'fly', 'turn', 'move', 'go',\n",
    "                    \n",
    "                    \n",
    "                    #backward\n",
    "                    'backward', 'back' , 'reverse' , 'back out', 'backwards',\n",
    "                    \n",
    "                    #down\n",
    "                    'down', 'drop', 'fall',\n",
    "                    \n",
    "                    #forward\n",
    "                    'forward', 'straight', 'ahead', 'forward', 'in',\n",
    "                    \n",
    "                    #right\n",
    "                    'left',\n",
    "                    \n",
    "                    #right\n",
    "                    'right',\n",
    "                    \n",
    "                    \n",
    "                    #up\n",
    "                    'up', 'lift', 'start',\n",
    "                    \n",
    "                    #yes\n",
    "                    'yes','ok', 'sure', 'yea', 'yup'\n",
    "                    \n",
    "                    ]\n",
    "\n",
    "used_emergency_phrases = []\n",
    "used_movement_phrases = []\n",
    "used_other_phrases = []\n",
    "\n",
    "print(\"Starting data loading...\")\n",
    "#  Loop through each data set ('clean_audio', 'noisy_audio') \n",
    "for data_set in SETS_TO_PROCESS:\n",
    "    set_path = os.path.join(DATA, data_set)\n",
    "    \n",
    "    if not os.path.isdir(set_path):\n",
    "        print(f\"Warning: Directory not found, skipping: {set_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing set: {set_path}\")\n",
    "    #  Loop through each keyword folder ('backward', 'down', etc.) \n",
    "    for keyword_folder in os.listdir(set_path):\n",
    "        keyword_path = os.path.join(set_path, keyword_folder)\n",
    "        if not os.path.isdir(keyword_path):\n",
    "            continue\n",
    "\n",
    "        \n",
    "        if keyword_folder in emergency_phrases:\n",
    "            label = 'emergency'\n",
    "            if keyword_folder not in used_emergency_phrases:\n",
    "                used_emergency_phrases.append(keyword_folder)\n",
    "        elif keyword_folder in movement_phrases:\n",
    "            label = 'movement'\n",
    "            if keyword_folder not in used_movement_phrases:\n",
    "                used_movement_phrases.append(keyword_folder)\n",
    "        else:\n",
    "            label = 'other'\n",
    "            if keyword_folder not in used_other_phrases:\n",
    "                used_other_phrases.append(keyword_folder)\n",
    "   \n",
    "            \n",
    "        # --- Loop through each .wav file ---\n",
    "        for file in os.listdir(keyword_path):    \n",
    "            if file.endswith(\".wav\"):\n",
    "                y_labels.append(label)\n",
    "                \n",
    "                # Load and process the audio file\n",
    "                path = os.path.join(keyword_path, file)\n",
    "                audio, _ = librosa.load(path, sr=sample_rate, duration=duration)\n",
    "                \n",
    "                if len(audio) < sample_rate:\n",
    "                    audio = np.pad(audio, (0, sample_rate - len(audio)))\n",
    "                else:\n",
    "                    audio = audio[:sample_rate]\n",
    "\n",
    "                # Feature extraction\n",
    "                mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
    "                mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "                mel_spec_db = mel_spec_db / 80.0 + 1.0  \n",
    "                x_data.append(mel_spec_db)\n",
    "\n",
    "print(\"Data loading complete.\")\n",
    "\n",
    "\n",
    "x_train = np.array(x_data)\n",
    "x_train = x_train[..., np.newaxis]\n",
    "current_frames = x_train.shape[2]\n",
    "if current_frames < desired_frames:\n",
    "    pad_width = ((0, 0), (0, 0), (0, desired_frames - current_frames), (0, 0))\n",
    "    x_train = np.pad(x_train, pad_width, mode='constant')\n",
    "elif current_frames > desired_frames:\n",
    "    x_train = x_train[:, :, :desired_frames, :]\n",
    "\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_doa_int = label_encoder.fit_transform(y_labels)\n",
    "\n",
    "y_doa = to_categorical(y_doa_int) \n",
    "y_sed = np.ones((len(y_doa), 1))\n",
    "\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"\\n✅ Found {num_classes} unique classes: {label_encoder.classes_}\")\n",
    "print('movement_phrases:', used_movement_phrases)\n",
    "print('emergency_phrases:', used_emergency_phrases)\n",
    "print('other_phrases:', used_other_phrases)\n",
    "print(f\"Number of samples: {len(x_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfea0c-3f25-4ade-90ad-5a3293bd5cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Permute, Reshape, GlobalAveragePooling1D, Dropout, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_resnet_conformer_seld(input_shape=(61,256,6), num_layers=1, head_size=32, num_heads=4, ff_dim=256, dropout_rate=0.15, fnn_units=[128]):\n",
    "\n",
    "    spec_input = Input(shape=input_shape)\n",
    "\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(spec_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 4))(x) \n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 4))(x) \n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "\n",
    "    \n",
    "    x = Permute((1, 2, 3))(x)\n",
    "    x = Reshape((input_shape[0], -1))(x)\n",
    "    \n",
    "    for i in range(num_layers):\n",
    "        x = branchformer_block(x, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout_rate, block_idx=i)\n",
    "\n",
    "    embedding_output = GlobalAveragePooling1D(name='embedding_output')(x)\n",
    "\n",
    "    sed_output = Dense(fnn_units[0], activation='relu', name=\"sed_dense\")(embedding_output)\n",
    "    sed_output = Dropout(dropout_rate, name=\"sed_dropout\")(sed_output)\n",
    "    sed_output = Dense(1, activation='sigmoid', name='sed_output')(sed_output)\n",
    "\n",
    "    doa_output = Dense(fnn_units[0], activation='relu', name=\"doa_dense\")(embedding_output)\n",
    "    doa_output = Dropout(dropout_rate, name=\"doa_dropout\")(doa_output)\n",
    "    doa_output = Dense(num_classes, activation='softmax', name='doa_output')(doa_output)\n",
    "    \n",
    "    full_model = Model(inputs=spec_input, outputs=[sed_output, doa_output, embedding_output])\n",
    "    train_model = Model(inputs=spec_input, outputs=[sed_output, doa_output])\n",
    "\n",
    "    return full_model, train_model\n",
    "\n",
    "full_model, train_model = build_resnet_conformer_seld(input_shape=(256, 61, 1))\n",
    "\n",
    "train_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.00008), \n",
    "    # loss=['binary_crossentropy', masked_categorical_crossentropy],  \n",
    "    loss_weights=[10.0, 10.0]  \n",
    ")\n",
    "\n",
    "train_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a6e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Compiling model...\")\n",
    "train_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss={\n",
    "        'sed_output': 'binary_crossentropy',\n",
    "        'doa_output': 'categorical_crossentropy'\n",
    "    },\n",
    "    loss_weights={\n",
    "        'sed_output': 1.0,\n",
    "        'doa_output': 0.0\n",
    "          }\n",
    ")\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "history = train_model.fit(x_train, [y_sed, y_doa], epochs=170, batch_size=64)\n",
    "print(\"✅ Training complete.\")\n",
    "\n",
    "print(\"\\nGenerating training loss graph...\")\n",
    "\n",
    "loss_history = history.history\n",
    "\n",
    "\n",
    "total_loss = loss_history['loss']\n",
    "sed_loss = loss_history['sed_output_loss']\n",
    "doa_loss = loss_history['doa_output_loss']\n",
    "\n",
    "epochs = range(1, len(total_loss) + 1)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, total_loss, 'r', label='Total Loss')\n",
    "plt.plot(epochs, doa_loss, 'b', label='Word Prediction Loss (DOA)')\n",
    "plt.plot(epochs, sed_loss, 'g', label='Event Detection Loss (SED)')\n",
    "plt.title('Model Training Losses')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\n--- Finding Best Epoch ---\")\n",
    "best_epoch_index = np.argmin(total_loss)\n",
    "min_loss = total_loss[best_epoch_index]\n",
    "print(f\"✅ Best Epoch: #{best_epoch_index + 1}\")\n",
    "print(f\"   - Minimum Total Loss: {min_loss:.4f}\")\n",
    "\n",
    "print(\"\\nSaving model and label encoder...\")\n",
    "model_path = 'model.keras'\n",
    "train_model.save(model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "encoder_path = 'label_encoder.joblib'\n",
    "joblib.dump(label_encoder, encoder_path)\n",
    "print(f\"LabelEncoder saved to: {encoder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "model_path = 'drone_up_model.keras'\n",
    "train_model = tf.keras.models.load_model(model_path, compile=False, safe_mode=False)\n",
    "print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "encoder_path = 'drone_up_label_encoder.joblib'\n",
    "label_encoder = joblib.load(encoder_path)\n",
    "print(f\"LabelEncoder loaded from {encoder_path}\")\n",
    "\n",
    "TEST_DATA_DIR = \"/Users/neilkalipersad/Desktop/Research Lab Files/ML Program Code/test_audio/\"\n",
    "\n",
    "\n",
    "def process_audio_for_prediction(file_paths, sr=16000, n_mels=256, duration=1.0, desired_frames=61):\n",
    "    x_data = []\n",
    "    for path in file_paths:\n",
    "        audio, _ = librosa.load(path, sr=sr, duration=duration)\n",
    "        if len(audio) < sr * duration:\n",
    "            audio = np.pad(audio, (0, int(sr * duration) - len(audio)))\n",
    "        else:\n",
    "            audio = audio[:int(sr * duration)]\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        mel_spec_db = mel_spec_db / 80.0 + 1.0\n",
    "        x_data.append(mel_spec_db)\n",
    "\n",
    "    x_batch = np.array(x_data)\n",
    "    x_batch = x_batch[..., np.newaxis]\n",
    "    current_frames = x_batch.shape[2]\n",
    "    if current_frames < desired_frames:\n",
    "        pad_width = ((0, 0), (0, 0), (0, desired_frames - current_frames), (0, 0))\n",
    "        x_batch = np.pad(x_batch, pad_width, mode='constant')\n",
    "    elif current_frames > desired_frames:\n",
    "        x_batch = x_batch[:, :, :desired_frames, :]\n",
    "    return x_batch\n",
    "\n",
    "# --- 3. Predict and Interpret Results ---\n",
    "test_files = [os.path.join(TEST_DATA_DIR, f) for f in os.listdir(TEST_DATA_DIR) if f.endswith('.wav')]\n",
    "\n",
    "if not test_files:\n",
    "    print(f\"⚠️ No .wav files found in '{TEST_DATA_DIR}'. Please check the path.\")\n",
    "else:\n",
    "    x_test = process_audio_for_prediction(test_files)\n",
    "    predictions = train_model.predict(x_test)\n",
    "    word_predictions = predictions[1]\n",
    "    predicted_indices = np.argmax(word_predictions, axis=1)\n",
    "    predicted_words = label_encoder.inverse_transform(predicted_indices)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(test_files)\n",
    "\n",
    "    print(\"\\n--- Prediction Results ---\")\n",
    "    for i in range(total_predictions):\n",
    "        filename = os.path.basename(test_files[i])\n",
    "        confidence = np.max(word_predictions[i])\n",
    "        \n",
    "        # Get the true label from the filename\n",
    "        true_label = filename.split('_')[1]\n",
    "        predicted_label = predicted_words[i]\n",
    "\n",
    "        print(f\"File: {filename}\")\n",
    "        print(f\"  - True Label: '{true_label}'\")\n",
    "        print(f\"  - Predicted Intent: '{predicted_label}' (Confidence: {confidence:.2f})\")\n",
    "\n",
    "        # Compare prediction to the true label\n",
    "        if predicted_label == true_label:\n",
    "            correct_predictions += 1\n",
    "            print(\"  - Result: Correct ✅\")\n",
    "        else:\n",
    "            print(\"  - Result: Incorrect ❌\")\n",
    "        print(\"-\" * 25)\n",
    "\n",
    "    if total_predictions > 0:\n",
    "        accuracy = (correct_predictions / total_predictions) * 100\n",
    "        print(\"\\n--- Final Tally ---\")\n",
    "        print(f\"Total Correct Predictions: {correct_predictions}\")\n",
    "        print(f\"Total Incorrect Predictions: {total_predictions - correct_predictions}\")\n",
    "        print(f\"Accuracy: {accuracy:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
