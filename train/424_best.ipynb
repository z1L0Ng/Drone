{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9e9594d-9d00-4969-b90a-3ea04631adfb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      2\u001b[39m tf.config.experimental.enable_tensor_float_32_execution(\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.enable_tensor_float_32_execution(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a69384e-84d5-40e6-a661-c7e4e3125a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "\n",
    "if gpus:\n",
    "    try:\n",
    "   \n",
    "        tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "        \n",
    "       \n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[1],\n",
    "            [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=32768)]\n",
    "        )\n",
    "\n",
    "      \n",
    "        \n",
    "        print(f\"Successfully configured GPU {gpus[1]} with memory limit of 2048MB and memory growth enabled.\")\n",
    "    \n",
    "    except RuntimeError as e:\n",
    "        print(\"Error during GPU configuration:\", e)\n",
    "else:\n",
    "    print(\"No GPU found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "076d2c1e-ca1d-4967-b0ba-d5c2bb7df0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84baf1ae-0231-45c7-a8ce-bb60c4a42e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "tf.config.set_visible_devices(gpus, 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148160b6-c747-4526-ad2c-31026082060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "\n",
    "\n",
    "a = tf.constant([[1.0, 2.0], [3.0, 4.0]])\n",
    "b = tf.constant([[1.0, 1.0], [0.0, 1.0]])\n",
    "c = tf.matmul(a, b)\n",
    "\n",
    "print(\"Result of matrix multiplication: \\n\", c.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58b98d5e-5e37-4108-9cba-8baf45748c30",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtf\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m backend \u001b[38;5;28;01mas\u001b[39;00m K\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mkeras\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodels\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.losses import binary_crossentropy\n",
    "from keras.layers import (\n",
    "    Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout,\n",
    "    Permute, Reshape, Bidirectional, GRU, TimeDistributed, Dense,\n",
    "    LayerNormalization, Add, MultiHeadAttention, GlobalAveragePooling1D\n",
    ")\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Reshape, Permute, GlobalAveragePooling1D, Add, LayerNormalization, MultiHeadAttention\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from keras.layers import Input, Dense, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Permute, Reshape, GlobalAveragePooling1D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "import keras.backend as K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddcec7c-22db-4a23-8523-6f578e49a6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.layers import MultiHeadAttention, Dense, LayerNormalization, Conv1D, Add, Dropout\n",
    "\n",
    "# def conformer_block(x, head_size, num_heads, ff_dim, dropout=0.1, kernel_size=31):\n",
    "#     # Feed Forward Module (first half)\n",
    "#     ff1 = Dense(ff_dim, activation='relu')(x)\n",
    "#     ff1 = Dropout(dropout)(ff1)\n",
    "#     ff1 = Dense(x.shape[-1])(ff1)\n",
    "#     x = Add()([x, 0.5 * ff1])\n",
    "\n",
    "#     # Multi-Head Self Attention Module\n",
    "#     attn = LayerNormalization(epsilon=1e-6)(x)\n",
    "#     attn = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(attn, attn)\n",
    "#     attn = Dropout(dropout)(attn)\n",
    "#     x = Add()([x, attn])\n",
    "\n",
    "#     # Convolution Module\n",
    "#     conv = LayerNormalization(epsilon=1e-6)(x)\n",
    "#     conv = Conv1D(filters=x.shape[-1], kernel_size=1, padding='same', activation='relu')(conv)\n",
    "#     conv = Conv1D(filters=x.shape[-1], kernel_size=kernel_size, padding='same', activation='relu', groups=x.shape[-1])(conv)\n",
    "#     conv = Conv1D(filters=x.shape[-1], kernel_size=1, padding='same')(conv)\n",
    "#     conv = Dropout(dropout)(conv)\n",
    "#     x = Add()([x, conv])\n",
    "\n",
    "#     # Feed Forward Module (second half)\n",
    "#     ff2 = Dense(ff_dim, activation='relu')(x)\n",
    "#     ff2 = Dropout(dropout)(ff2)\n",
    "#     ff2 = Dense(x.shape[-1])(ff2)\n",
    "#     x = Add()([x, 0.5 * ff2])\n",
    "\n",
    "#     # Final Layer Norm\n",
    "#     x = LayerNormalization(epsilon=1e-6)(x)\n",
    "#     return x\n",
    "import tensorflow as tf\n",
    "from keras.layers import LayerNormalization, Dense, Dropout, MultiHeadAttention, Conv1D, Add, Multiply, Lambda, Activation, DepthwiseConv1D, BatchNormalization\n",
    "\n",
    "def branchformer_block(x, head_size, num_heads, ff_dim, dropout=0.1, kernel_size=31, block_idx=0):\n",
    "    prefix = f\"branchformer{block_idx}\"\n",
    "\n",
    "    # FFN Module (first half)\n",
    "    ff1 = Dense(ff_dim, activation='relu', name=f\"{prefix}_ff1_dense1\")(x)\n",
    "    ff1 = Dropout(dropout, name=f\"{prefix}_ff1_dropout\")(ff1)\n",
    "    ff1 = Dense(x.shape[-1], name=f\"{prefix}_ff1_dense2\")(ff1)\n",
    "    x = Add(name=f\"{prefix}_ff1_add\")([x, Lambda(lambda z: 0.5 * z)(ff1)])\n",
    "\n",
    "    # Multi-Head Attention Branch\n",
    "    x_ln_attn = LayerNormalization(epsilon=1e-6, name=f\"{prefix}_attn_ln\")(x)\n",
    "    attn_out = MultiHeadAttention(\n",
    "        num_heads=num_heads,\n",
    "        key_dim=head_size,\n",
    "        dropout=dropout,\n",
    "        name=f\"{prefix}_attn\"\n",
    "    )(x_ln_attn, x_ln_attn)\n",
    "    attn_out = Dropout(dropout, name=f\"{prefix}_attn_dropout\")(attn_out)\n",
    "\n",
    "    # Convolution Branch\n",
    "    conv_input = LayerNormalization(epsilon=1e-6, name=f\"{prefix}_conv_ln\")(x)\n",
    "\n",
    "\n",
    "    conv_u = Conv1D(filters=x.shape[-1], kernel_size=1, padding='same', name=f\"{prefix}_conv_u\")(conv_input)\n",
    "    conv_v = Conv1D(filters=x.shape[-1], kernel_size=1, padding='same', activation='sigmoid', name=f\"{prefix}_conv_v\")(conv_input)\n",
    "    \n",
    "    # Create the Gated Linear Unit output\n",
    "    conv_glu = Multiply(name=f\"{prefix}_glu_out\")([conv_u, conv_v])\n",
    "    # --- END OF CORRECTION ---\n",
    "\n",
    "    # Depthwise Conv\n",
    "    conv_dw = DepthwiseConv1D(kernel_size=kernel_size, padding='same', name=f\"{prefix}_depthwise\")(conv_glu)\n",
    "    conv_dw = BatchNormalization(name=f\"{prefix}_dw_bn\")(conv_dw)\n",
    "    conv_dw = Activation('swish', name=f\"{prefix}_swish\")(conv_dw)\n",
    "    \n",
    "    # Pointwise Conv + Dropout\n",
    "    conv_out = Conv1D(filters=x.shape[-1], kernel_size=1, padding='same', name=f\"{prefix}_conv_pw2\")(conv_dw)\n",
    "    conv_out = Dropout(dropout, name=f\"{prefix}_conv_dropout\")(conv_out)\n",
    "    \n",
    "    # Merge Branches\n",
    "    merged = Add(name=f\"{prefix}_merge\")([attn_out, conv_out])\n",
    "    x = Add(name=f\"{prefix}_residual_merge\")([x, merged])\n",
    "\n",
    "    # FFN Module (second half)\n",
    "    ff2 = Dense(ff_dim, activation='relu', name=f\"{prefix}_ff2_dense1\")(x)\n",
    "    ff2 = Dropout(dropout, name=f\"{prefix}_ff2_dropout\")(ff2)\n",
    "    ff2 = Dense(x.shape[-1], name=f\"{prefix}_ff2_dense2\")(ff2)\n",
    "    x = Add(name=f\"{prefix}_ff2_add\")([x, Lambda(lambda z: 0.5 * z)(ff2)])\n",
    "\n",
    "    # Final Layer Norm\n",
    "    x = LayerNormalization(epsilon=1e-6, name=f\"{prefix}_ln_out\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9237601-7238-4e4d-989f-e344c3dbd31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras.backend as K\n",
    "\n",
    "# def masked_categorical_crossentropy(y_true, y_pred):\n",
    "\n",
    "#     # categorical_crossentropy (None, 8)\n",
    "#     loss = K.categorical_crossentropy(y_true, y_pred)\n",
    "\n",
    "    \n",
    "#     mask = K.cast(K.any(y_true > 0, axis=-1), K.floatx())  # (None,)\n",
    "\n",
    "#     #  Loss\n",
    "#     masked_loss = loss * mask  # (None, 8) * (None,) -> (None, 8)\n",
    "\n",
    "#     valid_samples = K.maximum(K.sum(mask), 1.0)  \n",
    "\n",
    "\n",
    "#     return K.sum(masked_loss) / valid_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9002b8ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''PREPROCESSING BLOCK'''\n",
    "# wav -> stft -> mel spec \n",
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "#DATA = \"/Users/neilkalipersad/Desktop/Research Lab Files/ML Program Code/all_audio/\"\n",
    "DATA = \"/datasets_prepare/datasets/speech-commands\"\n",
    "SETS_TO_PROCESS = ['clean_audio', 'noisy_audio']\n",
    "\n",
    "# --- Parameters ---\n",
    "sample_rate = 16000\n",
    "duration = 1.0 \n",
    "n_mels = 256\n",
    "desired_frames = 61\n",
    "\n",
    "# --- Initialize empty lists ---\n",
    "x_data = []\n",
    "y_labels = []\n",
    "\n",
    "emergency_phrases = [\n",
    "                    #stop\n",
    "                    'stop','stop flying', 'halt', 'freeze', 'cease', 'terminate', 'abort', 'wait', 'stay', 'pause', 'hold', 'brake', 'end', 'cut', \n",
    "\n",
    "                     #no\n",
    "                    'no', 'nope',\n",
    "                    \n",
    "                    #screams\n",
    "                    'ahh', 'ah', 'woah', 'wow',\n",
    "                    \n",
    "                    #profanity\n",
    "                    'shit', 'fuck', 'god', 'damn' 'crap'\n",
    "                     \n",
    "                     ]\n",
    "movement_phrases = [\n",
    "                    #general\n",
    "                    'hover', 'fly', 'turn', 'move', 'go',\n",
    "                    \n",
    "                    \n",
    "                    #backward\n",
    "                    'backward', 'back' , 'reverse' , 'back out', 'backwards',\n",
    "                    \n",
    "                    #down\n",
    "                    'down', 'drop', 'fall',\n",
    "                    \n",
    "                    #forward\n",
    "                    'forward', 'straight', 'ahead', 'forward', 'in',\n",
    "                    \n",
    "                    #right\n",
    "                    'left',\n",
    "                    \n",
    "                    #right\n",
    "                    'right',\n",
    "                    \n",
    "                    \n",
    "                    #up\n",
    "                    'up', 'lift', 'start',\n",
    "                    \n",
    "                    #yes\n",
    "                    'yes','ok', 'sure', 'yea', 'yup'\n",
    "                    \n",
    "                    ]\n",
    "\n",
    "used_emergency_phrases = []\n",
    "used_movement_phrases = []\n",
    "\n",
    "print(\"Starting data loading...\")\n",
    "#  Loop through each data set ('clean_audio', 'noisy_audio') \n",
    "for data_set in SETS_TO_PROCESS:\n",
    "    set_path = os.path.join(DATA, data_set)\n",
    "    \n",
    "    if not os.path.isdir(set_path):\n",
    "        print(f\"Warning: Directory not found, skipping: {set_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Processing set: {set_path}\")\n",
    "    #  Loop through each keyword folder ('backward', 'down', etc.) \n",
    "    for keyword_folder in os.listdir(set_path):\n",
    "        keyword_path = os.path.join(set_path, keyword_folder)\n",
    "        if not os.path.isdir(keyword_path):\n",
    "            continue\n",
    "\n",
    "        \n",
    "        if keyword_folder in emergency_phrases:\n",
    "            label = 'emergency'\n",
    "            if keyword_folder not in used_emergency_phrases:\n",
    "                used_emergency_phrases.append(keyword_folder)\n",
    "        elif keyword_folder in movement_phrases:\n",
    "            label = 'movement'\n",
    "            if keyword_folder not in used_movement_phrases:\n",
    "                used_movement_phrases.append(keyword_folder)\n",
    "        else:\n",
    "            #if it's not emergency or movement, remove it from the list\n",
    "            pass\n",
    "   \n",
    "            \n",
    "        # --- Loop through each .wav file ---\n",
    "        for file in os.listdir(keyword_path):    \n",
    "            if file.endswith(\".wav\"):\n",
    "                y_labels.append(label)\n",
    "                \n",
    "                # Load and process the audio file\n",
    "                path = os.path.join(keyword_path, file)\n",
    "                audio, _ = librosa.load(path, sr=sample_rate, duration=duration)\n",
    "                \n",
    "                if len(audio) < sample_rate:\n",
    "                    audio = np.pad(audio, (0, sample_rate - len(audio)))\n",
    "                else:\n",
    "                    audio = audio[:sample_rate]\n",
    "\n",
    "                # Feature extraction\n",
    "                mel_spec = librosa.feature.melspectrogram(y=audio, sr=sample_rate, n_mels=n_mels)\n",
    "                mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "                mel_spec_db = mel_spec_db / 80.0 + 1.0\n",
    "                x_data.append(mel_spec_db)\n",
    "\n",
    "print(\"Data loading complete.\")\n",
    "\n",
    "\n",
    "x_train = np.array(x_data)\n",
    "x_train = x_train[..., np.newaxis]\n",
    "current_frames = x_train.shape[2]\n",
    "if current_frames < desired_frames:\n",
    "    pad_width = ((0, 0), (0, 0), (0, desired_frames - current_frames), (0, 0))\n",
    "    x_train = np.pad(x_train, pad_width, mode='constant')\n",
    "elif current_frames > desired_frames:\n",
    "    x_train = x_train[:, :, :desired_frames, :]\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_labels_int = label_encoder.fit_transform(y_labels)\n",
    "num_classes = len(label_encoder.classes_)\n",
    "print(f\"\\n✅ Found {num_classes} unique classes: {label_encoder.classes_}\")\n",
    "print('movement_phrases:', used_movement_phrases)\n",
    "print('emergency_phrases:', used_emergency_phrases)\n",
    "print(f\"Number of samples: {len(x_train)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dfea0c-3f25-4ade-90ad-5a3293bd5cba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Input, Permute, Reshape, GlobalAveragePooling1D, Dropout, Dense\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_resnet_conformer_seld(input_shape=(61,256,6), num_layers=1, head_size=32, num_heads=4, ff_dim=256, dropout_rate=0.15, fnn_units=[128]):\n",
    "\n",
    "    spec_input = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(spec_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 4))(x) \n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 4))(x) \n",
    "\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(1, 2))(x)\n",
    "\n",
    "    x = Permute((1, 2, 3))(x)\n",
    "    x = Reshape((input_shape[0], -1))(x)\n",
    "\n",
    "    for i in range(num_layers):\n",
    "        x = branchformer_block(x, head_size=head_size, num_heads=num_heads, ff_dim=ff_dim, dropout=dropout_rate, block_idx=i)\n",
    "\n",
    "    embedding_output = GlobalAveragePooling1D(name='embedding_output')(x)\n",
    "\n",
    "    sed_output = Dense(fnn_units[0], activation='relu', name=\"sed_dense\")(embedding_output)\n",
    "    sed_output = Dropout(dropout_rate, name=\"sed_dropout\")(sed_output)\n",
    "    sed_output = Dense(1, activation='sigmoid', name='sed_output')(sed_output)\n",
    "\n",
    "    train_model = Model(inputs=spec_input, outputs=sed_output)\n",
    "\n",
    "    return train_model\n",
    "\n",
    "train_model = build_resnet_conformer_seld(input_shape=(256, 61, 1))\n",
    "\n",
    "train_model.compile(\n",
    "    optimizer=Adam(learning_rate=0.00008), \n",
    "    \n",
    "    #suggested to not use biniary_crossentropy\n",
    "    loss='categorical_crossentropy' \n",
    " )\n",
    "\n",
    "train_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a6e7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjoblib\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mCompiling model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m train_model.compile(\n\u001b[32m      6\u001b[39m     optimizer=\u001b[33m'\u001b[39m\u001b[33madam\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      7\u001b[39m     loss={\n\u001b[32m      8\u001b[39m         \u001b[33m'\u001b[39m\u001b[33msed_output\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mbinary_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      9\u001b[39m     },\n\u001b[32m     10\u001b[39m )\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"Compiling model...\")\n",
    "train_model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    ")\n",
    "\n",
    "print(\"Starting model training...\")\n",
    "history = train_model.fit(x_train, y_labels_int, epochs=170, batch_size=64)\n",
    "print(\"✅ Training complete.\")\n",
    "\n",
    "print(\"\\nGenerating training loss graph...\")\n",
    "\n",
    "loss_history = history.history\n",
    "\n",
    "\n",
    "total_loss = loss_history['loss']\n",
    "\n",
    "epochs = range(1, len(total_loss) + 1)\n",
    "\n",
    "# Plot the losses\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(epochs, total_loss, 'r', label='Total Loss')\n",
    "plt.title('Model Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- Finding Best Epoch ---\")\n",
    "best_epoch_index = np.argmin(total_loss)\n",
    "min_loss = total_loss[best_epoch_index]\n",
    "print(f\"Best Epoch: #{best_epoch_index + 1}\")\n",
    "print(f\"Minimum Total Loss: {min_loss:.4f}\")\n",
    "\n",
    "print(\"\\nSaving model and label encoder...\")\n",
    "model_path = 'model.keras'\n",
    "train_model.save(model_path)\n",
    "print(f\"Model saved to: {model_path}\")\n",
    "\n",
    "encoder_path = 'label_encoder.joblib'\n",
    "joblib.dump(label_encoder, encoder_path)\n",
    "print(f\"LabelEncoder saved to: {encoder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7272b5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib\n",
    "\n",
    "model_path = 'drone_model.keras'\n",
    "train_model = tf.keras.models.load_model(model_path, compile=False, safe_mode=False)\n",
    "print(f\"Model loaded from {model_path}\")\n",
    "\n",
    "encoder_path = 'drone_label_encoder.joblib'\n",
    "label_encoder = joblib.load(encoder_path)\n",
    "print(f\"LabelEncoder loaded from {encoder_path}\")\n",
    "\n",
    "TEST_DATA = None #\"/Users/neilkalipersad/Desktop/Research Lab Files/ML Program Code/test_audio/\"\n",
    "# need to create a test set maybe using anothe datbase\n",
    "\n",
    "def process_audio_for_prediction(file_paths, sr=16000, n_mels=256, duration=1.0, desired_frames=61):\n",
    "    x_data = []\n",
    "    for path in file_paths:\n",
    "        audio, _ = librosa.load(path, sr=sr, duration=duration)\n",
    "        if len(audio) < sr * duration:\n",
    "            audio = np.pad(audio, (0, int(sr * duration) - len(audio)))\n",
    "        else:\n",
    "            audio = audio[:int(sr * duration)]\n",
    "\n",
    "        mel_spec = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels)\n",
    "        mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)\n",
    "        mel_spec_db = mel_spec_db / 80.0 + 1.0\n",
    "        x_data.append(mel_spec_db)\n",
    "\n",
    "    x_batch = np.array(x_data)\n",
    "    x_batch = x_batch[..., np.newaxis]\n",
    "    current_frames = x_batch.shape[2]\n",
    "    if current_frames < desired_frames:\n",
    "        pad_width = ((0, 0), (0, 0), (0, desired_frames - current_frames), (0, 0))\n",
    "        x_batch = np.pad(x_batch, pad_width, mode='constant')\n",
    "    elif current_frames > desired_frames:\n",
    "        x_batch = x_batch[:, :, :desired_frames, :]\n",
    "    return x_batch\n",
    "\n",
    "#Predict Results  \n",
    "test_files = [os.path.join(TEST_DATA, f) for f in os.listdir(TEST_DATA) if f.endswith('.wav')]\n",
    "\n",
    "if not test_files:\n",
    "    print(f\"⚠️ No .wav files found in '{TEST_DATA}'. Please check the path.\")\n",
    "else:\n",
    "    x_test = process_audio_for_prediction(test_files)\n",
    "    predictions = train_model.predict(x_test)\n",
    "    predicted_labels = (predictions > 0.5).astype(int).flatten()\n",
    "    predicted_words = label_encoder.inverse_transform(predicted_labels)\n",
    "\n",
    "    correct_predictions = 0\n",
    "    total_predictions = len(test_files)\n",
    "\n",
    "    print(\"\\n--- Prediction Results ---\")\n",
    "    for i in range(total_predictions):\n",
    "        filename = os.path.basename(test_files[i])\n",
    "        confidence = predictions[i][0]\n",
    "        predicted_label = predicted_words[i]\n",
    "\n",
    "        print(f\"File: {filename}\")\n",
    "        print(f\"  - Predicted Label: '{predicted_label}' (Confidence: {confidence:.2f})\")\n",
    "        print(\"-\" * 25)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
